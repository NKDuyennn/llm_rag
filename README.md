# `LLM RAG` - Streamlit RAG Language Model App ğŸ¤–

## ğŸŒŸ Tá»•ng Quan 
Streamlit App nÃ y sá»­ dá»¥ng Retrieval-Augmented Generation (RAG) káº¿t há»£p vá»›i Large Language Model (LLM) cá»§a Gemini vÃ  MongoDB, má»™t cÆ¡ sá»Ÿ dá»¯ liá»‡u cho phÃ©p lÆ°u trá»¯ vÃ  tÃ¬m kiáº¿m theo vector. á»¨ng dá»¥ng cho phÃ©p ngÆ°á»i dÃ¹ng táº£i lÃªn file PDF ğŸ“‚, Ä‘áº·t cÃ¢u há»i liÃªn quan Ä‘áº¿n ná»™i dung cá»§a cÃ¡c file nÃ y â“ vÃ  nháº­n cÃ¢u tráº£ lá»i Ä‘Æ°á»£c táº¡o ra bá»Ÿi AI-generated dá»±a trÃªn ná»™i dung Ä‘Ã£ táº£i lÃªn ğŸ“š. 

## ğŸ› ï¸ Cáº¥u trÃºc há»‡ thá»‘ng
SÆ¡ Ä‘á»“ dÆ°á»›i Ä‘Ã¢y minh há»a luá»“ng dá»¯ liá»‡u qua há»‡ thá»‘ng:
<p align="center">
  <img src="https://github.com/NKDuyennn/llm_rag/blob/nkduyen/image/diagram.jpg" width="100%" />
</p>  

- **LÆ°u Ã½** ğŸ’¡: CÃ³ thá»ƒ Ã¡p dá»¥ng cáº£ vá»›i nhá»¯ng nguá»“n dá»¯ liá»‡u á»Ÿ dáº¡ng báº£ng sáºµn, khÃ´ng cáº§n pháº£i xá»­ lÃ½ file PDF 

## â“ CÃ¡ch hoáº¡t Ä‘á»™ng:
á»¨ng dá»¥ng Streamlit LLM-RAG Ä‘Æ°á»£c chia thÃ nh 2 pháº§n:

<p align="center">
  <img src="https://github.com/labrijisaad/LLM-RAG/assets/74627083/61518120-e3a0-4e76-84ea-4fb11bd82e4a" width="60%" />
</p>

- **Setup Knowledge Base** ğŸ“‚: Upload markdown documents to establish the knowledge base.
- **Explore Knowledge Base** ğŸ”: Browse and manage the uploaded documents.
- **RAG Query** ğŸ’¡: Pose questions to receive answers referencing the knowledge base and the model's knowledge.

Additionally, the app offers advanced settings for customization based on user needs:

<p align="center">
  <img src="https://github.com/labrijisaad/LLM-RAG/assets/74627083/8f878a40-f268-4ba9-ae0f-75ca2391357d" width="30%" />
</p>

- **OpenAI Embedding Model Settings**: Select the embedding model for document vectorization.
- **OpenAI LLM Settings**: Choose the OpenAI language model variant for generating answers.
- **LLM Temperature**: Adjust the creativity of the modelâ€™s responses.
- **Max Completion Tokens**: Define the maximum length of the generated response.
- **Drop All Documents in Knowledge Base**: Clear the database by typing a confirmatory command.


## Project Structure ğŸ—ï¸
The project's main directories are laid out as follows:

```
LLM-RAG/
â”œâ”€â”€ .github/workflows/          # CI/CD pipeline definitions
â”œâ”€â”€ configs/                    # Configuration files for the model (model names, pricing..)
â”œâ”€â”€ data/                       # Data and indices used by the app (FAISS Knowledge Base)
â”œâ”€â”€ docker/                     # Docker related files 
â”œâ”€â”€ notebooks/                  # Jupyter notebooks for experiments
â”œâ”€â”€ secrets/                    # API keys and other secrets (excluded from version control)
â”œâ”€â”€ src/                        # Source code for the LLM RAG logic
â”œâ”€â”€ streamlit_app/              # Streamlit app files for the Web Interface
â”œâ”€â”€ tests/                      # Test cases for the application
â”œâ”€â”€ .dockerignore               # Specifies ignored files in Docker builds
â”œâ”€â”€ .gitignore                  # Specifies untracked files ignored by git
â”œâ”€â”€ Dockerfile                  # Dockerfile for building the Docker image
â”œâ”€â”€ Makefile                    # Make commands for building and running the app ğŸ§‘â€ğŸ’»
â”œâ”€â”€ README.md                   # Documentation and instructions
â”œâ”€â”€ requirements.txt            # Python dependencies for the project
â””â”€â”€ (additional project files and scripts)
```

## ğŸš€ Getting Started

To begin using the LLM RAG app, follow these simple steps:

1. **Clone the Repository:**
   ```
   git clone https://github.com/labrijisaad/LLM-RAG.git
   ```

2. **Create the Environment:**
   Set up your virtual environment using either venv or conda:
   ```
   # Using venv
   python -m venv env_llm_rag
   source env_llm_rag/bin/activate
   
   # Using conda
   conda create --name env_llm_rag
   conda activate env_llm_rag
   ```

3. **Install Dependencies:**
   Install the required dependencies by

 running:
   ```
   pip install -r requirements.txt
   ```

4. **Set Up OpenAI API:**
   Rename the example credentials file to `secrets/credentials.yml` and replace the placeholder key ('sk-xxx') with your actual OpenAI API key. You can obtain your API key by following the instructions provided in the [OpenAI documentation](https://platform.openai.com/docs/quickstart?context=python).
   ```
   rename secrets/credentials-example.yml secrets/credentials.yml
   ```

5. **Run the Streamlit App:**
   Launch the Streamlit app using either the provided Makefile command or directly via the Streamlit CLI:
   ```
   # Using Makefile
   make stream
   
   # Or directly
   streamlit run streamlit_app/main.py
   ```
## ğŸ³ Docker Version

The application is available as a Docker container and can be easily set up and run with a few commands. If you want to run the application using the Docker image from the public registry, ensure that you have a `secrets` directory with the necessary API keys as specified in the `secrets/credentials.yml`.

To pull and run the Docker container:

1. **Pull the Docker Image:**
   You can pull the image directly from **Google Artifact Registry** using the following command:
   ```shell
   docker pull europe-west1-docker.pkg.dev/llm-rag-application/llm-rag/llm_rag_app:latest
   ```

2. **Run the Docker Container:**
   After pulling the image, you can run it with:
   ```shell
   docker run -p 8501:8501 -v $(pwd)/secrets:/app/secrets europe-west1-docker.pkg.dev/llm-rag-application/llm-rag/llm_rag_app:latest
   ```
   This command will start the container and mount your **`secrets`** directory for the application to use.

If you prefer to use the **Makefile**, the equivalent commands are provided for convenience:

```shell
# To pull the Docker image
make docker-pull

# To run the pulled Docker image
make docker-run-pulled
```

The Streamlit app will be available at **`http://localhost:8501`** once the container is running.


## ğŸŒ Connect with me
<div align="center">
  <a href="https://www.linkedin.com/in/labrijisaad/">
    <img src="https://img.shields.io/badge/LinkedIn-%230077B5.svg?&style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn" style="margin-bottom: 5px;"/>
  </a>
  <a href="https://github.com/labrijisaad">
    <img src="https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white" alt="GitHub" style="margin-bottom: 5px;"/>
  </a>
</div>
